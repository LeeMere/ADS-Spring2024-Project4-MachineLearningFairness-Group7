{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52cd3502-dd48-4f3c-b614-4311721db496",
   "metadata": {},
   "source": [
    "# 5243 project4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e85af9-929d-4c62-919f-f47d105c2025",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aed0d756-3456-4a8e-abbb-a44a84e5f06a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy import optimize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd45b36f-5915-4585-890a-6fc3236eff54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "url = 'https://raw.githubusercontent.com/LeeMere/ADS-Spring2024-Project4-MachineLearningFairness-Group7/main/data/compas-scores-two-years.csv'\n",
    "df_raw = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b900147f-a714-47dd-bbba-87921d39902a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>compas_screening_date</th>\n",
       "      <th>sex</th>\n",
       "      <th>dob</th>\n",
       "      <th>age</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>race</th>\n",
       "      <th>...</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>v_score_text</th>\n",
       "      <th>v_screening_date</th>\n",
       "      <th>in_custody</th>\n",
       "      <th>out_custody</th>\n",
       "      <th>priors_count.1</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>event</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>miguel hernandez</td>\n",
       "      <td>miguel</td>\n",
       "      <td>hernandez</td>\n",
       "      <td>2013-08-14</td>\n",
       "      <td>Male</td>\n",
       "      <td>1947-04-18</td>\n",
       "      <td>69</td>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-08-14</td>\n",
       "      <td>2014-07-07</td>\n",
       "      <td>2014-07-14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>327</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>kevon dixon</td>\n",
       "      <td>kevon</td>\n",
       "      <td>dixon</td>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>Male</td>\n",
       "      <td>1982-01-22</td>\n",
       "      <td>34</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>2013-01-26</td>\n",
       "      <td>2013-02-05</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>ed philo</td>\n",
       "      <td>ed</td>\n",
       "      <td>philo</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>Male</td>\n",
       "      <td>1991-05-14</td>\n",
       "      <td>24</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>marcu brown</td>\n",
       "      <td>marcu</td>\n",
       "      <td>brown</td>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>Male</td>\n",
       "      <td>1993-01-21</td>\n",
       "      <td>23</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>bouthy pierrelouis</td>\n",
       "      <td>bouthy</td>\n",
       "      <td>pierrelouis</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>Male</td>\n",
       "      <td>1973-01-22</td>\n",
       "      <td>43</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                name   first         last compas_screening_date   sex  \\\n",
       "0   1    miguel hernandez  miguel    hernandez            2013-08-14  Male   \n",
       "1   3         kevon dixon   kevon        dixon            2013-01-27  Male   \n",
       "2   4            ed philo      ed        philo            2013-04-14  Male   \n",
       "3   5         marcu brown   marcu        brown            2013-01-13  Male   \n",
       "4   6  bouthy pierrelouis  bouthy  pierrelouis            2013-03-26  Male   \n",
       "\n",
       "          dob  age          age_cat              race  ...  v_decile_score  \\\n",
       "0  1947-04-18   69  Greater than 45             Other  ...               1   \n",
       "1  1982-01-22   34          25 - 45  African-American  ...               1   \n",
       "2  1991-05-14   24     Less than 25  African-American  ...               3   \n",
       "3  1993-01-21   23     Less than 25  African-American  ...               6   \n",
       "4  1973-01-22   43          25 - 45             Other  ...               1   \n",
       "\n",
       "   v_score_text  v_screening_date  in_custody  out_custody  priors_count.1  \\\n",
       "0           Low        2013-08-14  2014-07-07   2014-07-14               0   \n",
       "1           Low        2013-01-27  2013-01-26   2013-02-05               0   \n",
       "2           Low        2013-04-14  2013-06-16   2013-06-16               4   \n",
       "3        Medium        2013-01-13         NaN          NaN               1   \n",
       "4           Low        2013-03-26         NaN          NaN               2   \n",
       "\n",
       "  start   end event two_year_recid  \n",
       "0     0   327     0              0  \n",
       "1     9   159     1              1  \n",
       "2     0    63     0              1  \n",
       "3     0  1174     0              0  \n",
       "4     0  1102     0              0  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8aaebb6e-b553-4988-8f8e-88f34f56e3df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7214 entries, 0 to 7213\n",
      "Data columns (total 53 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       7214 non-null   int64  \n",
      " 1   name                     7214 non-null   object \n",
      " 2   first                    7214 non-null   object \n",
      " 3   last                     7214 non-null   object \n",
      " 4   compas_screening_date    7214 non-null   object \n",
      " 5   sex                      7214 non-null   object \n",
      " 6   dob                      7214 non-null   object \n",
      " 7   age                      7214 non-null   int64  \n",
      " 8   age_cat                  7214 non-null   object \n",
      " 9   race                     7214 non-null   object \n",
      " 10  juv_fel_count            7214 non-null   int64  \n",
      " 11  decile_score             7214 non-null   int64  \n",
      " 12  juv_misd_count           7214 non-null   int64  \n",
      " 13  juv_other_count          7214 non-null   int64  \n",
      " 14  priors_count             7214 non-null   int64  \n",
      " 15  days_b_screening_arrest  6907 non-null   float64\n",
      " 16  c_jail_in                6907 non-null   object \n",
      " 17  c_jail_out               6907 non-null   object \n",
      " 18  c_case_number            7192 non-null   object \n",
      " 19  c_offense_date           6055 non-null   object \n",
      " 20  c_arrest_date            1137 non-null   object \n",
      " 21  c_days_from_compas       7192 non-null   float64\n",
      " 22  c_charge_degree          7214 non-null   object \n",
      " 23  c_charge_desc            7185 non-null   object \n",
      " 24  is_recid                 7214 non-null   int64  \n",
      " 25  r_case_number            3471 non-null   object \n",
      " 26  r_charge_degree          3471 non-null   object \n",
      " 27  r_days_from_arrest       2316 non-null   float64\n",
      " 28  r_offense_date           3471 non-null   object \n",
      " 29  r_charge_desc            3413 non-null   object \n",
      " 30  r_jail_in                2316 non-null   object \n",
      " 31  r_jail_out               2316 non-null   object \n",
      " 32  violent_recid            0 non-null      float64\n",
      " 33  is_violent_recid         7214 non-null   int64  \n",
      " 34  vr_case_number           819 non-null    object \n",
      " 35  vr_charge_degree         819 non-null    object \n",
      " 36  vr_offense_date          819 non-null    object \n",
      " 37  vr_charge_desc           819 non-null    object \n",
      " 38  type_of_assessment       7214 non-null   object \n",
      " 39  decile_score.1           7214 non-null   int64  \n",
      " 40  score_text               7214 non-null   object \n",
      " 41  screening_date           7214 non-null   object \n",
      " 42  v_type_of_assessment     7214 non-null   object \n",
      " 43  v_decile_score           7214 non-null   int64  \n",
      " 44  v_score_text             7214 non-null   object \n",
      " 45  v_screening_date         7214 non-null   object \n",
      " 46  in_custody               6978 non-null   object \n",
      " 47  out_custody              6978 non-null   object \n",
      " 48  priors_count.1           7214 non-null   int64  \n",
      " 49  start                    7214 non-null   int64  \n",
      " 50  end                      7214 non-null   int64  \n",
      " 51  event                    7214 non-null   int64  \n",
      " 52  two_year_recid           7214 non-null   int64  \n",
      "dtypes: float64(4), int64(16), object(33)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae215fa7-d93b-4252-b38a-9f63986a8aa0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>violent_recid</th>\n",
       "      <td>7214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vr_charge_degree</th>\n",
       "      <td>6395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vr_case_number</th>\n",
       "      <td>6395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vr_offense_date</th>\n",
       "      <td>6395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vr_charge_desc</th>\n",
       "      <td>6395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_arrest_date</th>\n",
       "      <td>6077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r_jail_out</th>\n",
       "      <td>4898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r_jail_in</th>\n",
       "      <td>4898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r_days_from_arrest</th>\n",
       "      <td>4898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r_charge_desc</th>\n",
       "      <td>3801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r_offense_date</th>\n",
       "      <td>3743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r_case_number</th>\n",
       "      <td>3743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r_charge_degree</th>\n",
       "      <td>3743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_offense_date</th>\n",
       "      <td>1159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_jail_out</th>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>days_b_screening_arrest</th>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_jail_in</th>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out_custody</th>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_custody</th>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_charge_desc</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_days_from_compas</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_case_number</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         count\n",
       "violent_recid             7214\n",
       "vr_charge_degree          6395\n",
       "vr_case_number            6395\n",
       "vr_offense_date           6395\n",
       "vr_charge_desc            6395\n",
       "c_arrest_date             6077\n",
       "r_jail_out                4898\n",
       "r_jail_in                 4898\n",
       "r_days_from_arrest        4898\n",
       "r_charge_desc             3801\n",
       "r_offense_date            3743\n",
       "r_case_number             3743\n",
       "r_charge_degree           3743\n",
       "c_offense_date            1159\n",
       "c_jail_out                 307\n",
       "days_b_screening_arrest    307\n",
       "c_jail_in                  307\n",
       "out_custody                236\n",
       "in_custody                 236\n",
       "c_charge_desc               29\n",
       "c_days_from_compas          22\n",
       "c_case_number               22"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can see there are some missing data exist, check with the missing data\n",
    "\n",
    "missing_data = pd.DataFrame(df_raw.isna().sum()).sort_values(by = 0, ascending=False)\n",
    "missing_data.columns = [\"count\"]\n",
    "missing_data[missing_data[\"count\"]!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81e68f5a-1fe0-458a-a000-5f7da000c29e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter the DataFrame for the two races\n",
    "df_filtered = df_raw[df_raw['race'].isin(['Caucasian', 'African-American'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23493db5-5502-4239-9c49-3bde9ca4adc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Feature selection\n",
    "# Since we do not use the columns with missing data, we can ignore that\n",
    "features = ['age', 'race', 'sex', 'decile_score', 'priors_count']  # Example features\n",
    "X = df_filtered[features]\n",
    "y = df_filtered['two_year_recid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23dc7e4d-b10c-4ca7-be32-cbfaf9e539ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in the dataset:\n",
      "age             0\n",
      "race            0\n",
      "sex             0\n",
      "decile_score    0\n",
      "priors_count    0\n",
      "dtype: int64\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Check missing values again\n",
    "print(\"Missing values in the dataset:\")\n",
    "print(X.isnull().sum())\n",
    "print(y.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68b5cea3-0fe3-4ea7-ac7c-acf66cfe8bf5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vq/q7gqpwcx7hv4c3d6f0b3zk500000gn/T/ipykernel_26843/1437553385.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['race'] = X['race'].map({'Caucasian': 1, 'African-American': 0})\n",
      "/var/folders/vq/q7gqpwcx7hv4c3d6f0b3zk500000gn/T/ipykernel_26843/1437553385.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['sex'] = X['sex'].map({'Female': 0, 'Male': 1})\n"
     ]
    }
   ],
   "source": [
    "# Map variable to a binary variable\n",
    "X['race'] = X['race'].map({'Caucasian': 1, 'African-American': 0})\n",
    "X['sex'] = X['sex'].map({'Female': 0, 'Male': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9570e59e-bed6-4ed7-b5ce-dc746754283b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>decile_score</th>\n",
       "      <th>priors_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  race  sex  decile_score  priors_count\n",
       "1   34     0    1             3             0\n",
       "2   24     0    1             4             4\n",
       "3   23     0    1             8             1\n",
       "6   41     1    1             6            14\n",
       "8   39     1    0             1             0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf50fc83-0f5b-4ed5-b82c-2db94d065f37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check the lengths of X and y to make sure they match\n",
    "assert len(X) == len(y), \"The lengths of X and y do not match.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04fed7cb-79f2-4860-9a9a-55c4db280da9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>decile_score</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  race  sex  decile_score  priors_count  two_year_recid\n",
       "1   34     0    1             3             0               1\n",
       "2   24     0    1             4             4               1\n",
       "3   23     0    1             8             1               0\n",
       "6   41     1    1             6            14               1\n",
       "8   39     1    0             1             0               0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([X, y], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93b3442f-e530-4f29-9d23-3091aa7a3cf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#data splitting for baseline model\n",
    "train_size = int(len(df) * 0.714)\n",
    "remainder_size = int(len(df) * 0.143)\n",
    "\n",
    "train = df[:train_size]\n",
    "remainder = df[train_size:]\n",
    "\n",
    "validation = remainder[:remainder_size]\n",
    "test = remainder[remainder_size:]\n",
    "\n",
    "label = \"two_year_recid\"\n",
    "sensitive = \"race\"\n",
    "features = ['age', 'sex', 'decile_score', 'priors_count']\n",
    "features_race = ['race', 'age', 'race', 'sex', 'decile_score', 'priors_count']\n",
    "\n",
    "x_train, y_train, race_train = train[features], train[label].to_numpy(), train[sensitive]\n",
    "x_val, y_val, race_val = validation[features], validation[label].to_numpy(), validation[sensitive]\n",
    "x_test, y_test, race_test = test[features], test[label].to_numpy(), test[sensitive]\n",
    "\n",
    "x_train_race, x_test_race, x_val_race = train[features_race], test[features_race], validation[features_race]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4a6711-a430-4d62-b776-88e5e829527d",
   "metadata": {},
   "source": [
    "## 2. Baseline Model - Logistic Regression (Without Constraints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2a20429-5210-4d81-9f04-2af5285b82a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bsl = LogisticRegression().fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d2ae178-f4ef-4315-8b18-93e9305b7942",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_calibration(sensitive_attr, y_pred, y_true):\n",
    "    cau_index = np.where(sensitive_attr == 1)[0]\n",
    "    african_index = np.where(sensitive_attr == 0)[0]\n",
    "\n",
    "    y_pred_cau = y_pred[cau_index]\n",
    "    y_true_cau = y_true[cau_index]\n",
    "    Acc_cau = sum(y_pred_cau == y_true_cau)/len(y_pred_cau)\n",
    "\n",
    "    y_pred_african = y_pred[african_index]\n",
    "    y_true_african = y_true[african_index]\n",
    "    Acc_african = sum(y_pred_african == y_true_african)/len(y_pred_african)\n",
    "\n",
    "    calibration = abs(Acc_cau - Acc_african)\n",
    "    return(calibration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a52b7d59-7877-4540-a03a-46ede103e95a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Set</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Calibration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train</td>\n",
       "      <td>0.680938</td>\n",
       "      <td>0.012042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Validation</td>\n",
       "      <td>0.682594</td>\n",
       "      <td>0.005245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Test</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.047773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Set  Accuracy  Calibration\n",
       "0       Train  0.680938     0.012042\n",
       "1  Validation  0.682594     0.005245\n",
       "2        Test  0.650000     0.047773"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluating the baseline model\n",
    "summary_bsl = {\"Set\": [\"Train\", \"Validation\", \"Test\"],\n",
    "               \"Accuracy\":  [bsl.score(x_train, y_train), bsl.score(x_val, y_val), bsl.score(x_test, y_test)],\n",
    "               \"Calibration\": [calc_calibration(race_train, bsl.predict(x_train), y_train),\n",
    "                               calc_calibration(race_val, bsl.predict(x_val), y_val),\n",
    "                               calc_calibration(race_test, bsl.predict(x_test), y_test)]}\n",
    "pd.DataFrame(summary_bsl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1daead-ae38-4e41-81b7-a66b27184141",
   "metadata": {},
   "source": [
    "## Algorithm 2: Learning Fair Representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5b5f367-b4f3-44fa-b22b-eefc028e33bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 4391\n",
      "Validation set size: 879\n",
      "Testing set size: 880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vq/q7gqpwcx7hv4c3d6f0b3zk500000gn/T/ipykernel_26843/3565155174.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['sex'] = train['sex'].map({'Female': 0, 'Male': 1})\n",
      "/var/folders/vq/q7gqpwcx7hv4c3d6f0b3zk500000gn/T/ipykernel_26843/3565155174.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  validation['sex'] = validation['sex'].map({'Female': 0, 'Male': 1})\n",
      "/var/folders/vq/q7gqpwcx7hv4c3d6f0b3zk500000gn/T/ipykernel_26843/3565155174.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['sex'] = test['sex'].map({'Female': 0, 'Male': 1})\n",
      "/var/folders/vq/q7gqpwcx7hv4c3d6f0b3zk500000gn/T/ipykernel_26843/3565155174.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['race'] = train['race'].map({'African-American': 0, 'Caucasian': 1})\n",
      "/var/folders/vq/q7gqpwcx7hv4c3d6f0b3zk500000gn/T/ipykernel_26843/3565155174.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  validation['race'] = validation['race'].map({'African-American': 0, 'Caucasian': 1})\n",
      "/var/folders/vq/q7gqpwcx7hv4c3d6f0b3zk500000gn/T/ipykernel_26843/3565155174.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['race'] = test['race'].map({'African-American': 0, 'Caucasian': 1})\n"
     ]
    }
   ],
   "source": [
    "# data split for LFR\n",
    "df_filtered = df_raw[df_raw['race'].isin(['Caucasian', 'African-American'])]\n",
    "\n",
    "# Perform data splitting\n",
    "train_size = int(len(df_filtered) * 0.714)\n",
    "remainder_size = int(len(df_filtered) * 0.143)\n",
    "\n",
    "train = df_filtered[:train_size]\n",
    "remainder = df_filtered[train_size:]\n",
    "validation = remainder[:remainder_size]\n",
    "test = remainder[remainder_size:]\n",
    "\n",
    "# Define the features, label, and sensitive attribute\n",
    "features = ['age', 'sex', 'decile_score', 'priors_count']\n",
    "label = \"two_year_recid\"\n",
    "sensitive = \"race\"\n",
    "\n",
    "# Encode categorical variables\n",
    "train['sex'] = train['sex'].map({'Female': 0, 'Male': 1})\n",
    "validation['sex'] = validation['sex'].map({'Female': 0, 'Male': 1})\n",
    "test['sex'] = test['sex'].map({'Female': 0, 'Male': 1})\n",
    "\n",
    "train['race'] = train['race'].map({'African-American': 0, 'Caucasian': 1})\n",
    "validation['race'] = validation['race'].map({'African-American': 0, 'Caucasian': 1})\n",
    "test['race'] = test['race'].map({'African-American': 0, 'Caucasian': 1})\n",
    "\n",
    "# Define X_train, X_val, X_test, y_train, y_val, y_test, sensitive_train, sensitive_val, sensitive_test\n",
    "X_train, y_train, sensitive_train = train[features].values, train[label].values, train[sensitive].values\n",
    "X_val, y_val, sensitive_val = validation[features].values, validation[label].values, validation[sensitive].values\n",
    "X_test, y_test, sensitive_test = test[features].values, test[label].values, test[sensitive].values\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Validation set size: {len(X_val)}\")\n",
    "print(f\"Testing set size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a99a64a-77ef-4f74-b684-d20734dbb2ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the distance function using weighted Euclidean distance\n",
    "def weighted_euclidean_distance(x, v, alpha):\n",
    "    return np.sqrt(np.sum(alpha * (x - v)**2, axis=-1))\n",
    "\n",
    "# Define the probability matrix calculation function\n",
    "def calculate_probability_matrix(X, V, alpha):\n",
    "    num_samples, num_features = X.shape\n",
    "    num_prototypes = V.shape[0]\n",
    "    P = np.zeros((num_samples, num_prototypes))\n",
    "    for i in range(num_samples):\n",
    "        distances = weighted_euclidean_distance(X[i], V, alpha)\n",
    "        P[i] = np.exp(-distances) / np.sum(np.exp(-distances))\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f14d1b1-1e88-4423-b32d-ce0bc688d9aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the function to calculate the reconstruction of X and the associated loss\n",
    "def reconstruct_x_and_loss(X, P, V):\n",
    "    X_hat = np.dot(P, V)  # Reconstruction of X\n",
    "    Loss_X = np.mean((X - X_hat) ** 2)  # Reconstruction loss\n",
    "    return X_hat, Loss_X\n",
    "\n",
    "# Define the function to calculate the prediction of Y and the associated loss\n",
    "def predict_y_and_loss(P, w, y):\n",
    "    y_hat = np.dot(P, w)  # Prediction of Y\n",
    "    Loss_Y = -np.mean(y * np.log(y_hat) + (1 - y) * np.log(1 - y_hat))  # Prediction loss\n",
    "    return y_hat, Loss_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9174718-248c-42b0-aa3a-7dd4aefd5b72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the objective function for LFR\n",
    "def LFR_objective(params, X_sensitive, X_nonsensitive, y_sensitive, y_nonsensitive, num_prototypes, A_z, A_x, A_y):\n",
    "    num_features = X_sensitive.shape[1]\n",
    "    # Unpack parameters\n",
    "    alpha_sensitive = params[:num_features]\n",
    "    alpha_nonsensitive = params[num_features:2*num_features]\n",
    "    w = params[2*num_features:(2*num_features + num_prototypes)]\n",
    "    V = params[-(num_features * num_prototypes):].reshape((num_prototypes, num_features))\n",
    "\n",
    "    # Calculate probability matrices\n",
    "    P_sensitive = calculate_probability_matrix(X_sensitive, V, alpha_sensitive)\n",
    "    P_nonsensitive = calculate_probability_matrix(X_nonsensitive, V, alpha_nonsensitive)\n",
    "\n",
    "    # Calculate losses for sensitive group\n",
    "    X_hat_sensitive, Loss_X_sensitive = reconstruct_x_and_loss(X_sensitive, P_sensitive, V)\n",
    "    y_hat_sensitive, Loss_Y_sensitive = predict_y_and_loss(P_sensitive, w, y_sensitive)\n",
    "\n",
    "    # Calculate losses for nonsensitive group\n",
    "    X_hat_nonsensitive, Loss_X_nonsensitive = reconstruct_x_and_loss(X_nonsensitive, P_nonsensitive, V)\n",
    "    y_hat_nonsensitive, Loss_Y_nonsensitive = predict_y_and_loss(P_nonsensitive, w, y_nonsensitive)\n",
    "\n",
    "    # Calculate fairness loss\n",
    "    M_k_sensitive = P_sensitive.mean(axis=0)\n",
    "    M_k_nonsensitive = P_nonsensitive.mean(axis=0)\n",
    "    Loss_Z = np.abs(M_k_sensitive - M_k_nonsensitive).sum()\n",
    "\n",
    "    # Combine losses into final objective\n",
    "    objective = A_z * Loss_Z + A_x * (Loss_X_sensitive + Loss_X_nonsensitive) + A_y * (Loss_Y_sensitive + Loss_Y_nonsensitive)\n",
    "    return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7b2f42d-ef6b-4ba9-98f6-c35151b5e648",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the hyperparameters\n",
    "num_prototypes = 10\n",
    "A_z = 1\n",
    "A_x = 0.01\n",
    "A_y = 1\n",
    "\n",
    "# Initialize parameters\n",
    "num_features = X_train.shape[1]\n",
    "alpha_sensitive = np.ones(num_features)\n",
    "alpha_nonsensitive = np.ones(num_features)\n",
    "w = np.random.rand(num_prototypes)\n",
    "V = np.random.rand(num_prototypes, num_features)\n",
    "params_init = np.concatenate((alpha_sensitive, alpha_nonsensitive, w, V.flatten()))\n",
    "\n",
    "# Split the data into sensitive and nonsensitive groups\n",
    "X_sensitive_train = X_train[sensitive_train == 1]\n",
    "X_nonsensitive_train = X_train[sensitive_train == 0]\n",
    "y_sensitive_train = y_train[sensitive_train == 1]\n",
    "y_nonsensitive_train = y_train[sensitive_train == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c83b37bf-7a2e-4a57-95b9-099941f00244",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vq/q7gqpwcx7hv4c3d6f0b3zk500000gn/T/ipykernel_26843/2057028447.py:3: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return np.sqrt(np.sum(alpha * (x - v)**2, axis=-1))\n",
      "/var/folders/vq/q7gqpwcx7hv4c3d6f0b3zk500000gn/T/ipykernel_26843/1101398541.py:10: RuntimeWarning: invalid value encountered in log\n",
      "  Loss_Y = -np.mean(y * np.log(y_hat) + (1 - y) * np.log(1 - y_hat))  # Prediction loss\n",
      "/var/folders/vq/q7gqpwcx7hv4c3d6f0b3zk500000gn/T/ipykernel_26843/2057028447.py:12: RuntimeWarning: invalid value encountered in divide\n",
      "  P[i] = np.exp(-distances) / np.sum(np.exp(-distances))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5518\n",
      "Validation Calibration: 0.0673\n",
      "Test Accuracy: 0.5170\n",
      "Test Calibration: 0.1752\n"
     ]
    }
   ],
   "source": [
    "# Train the LFR model\n",
    "result = minimize(LFR_objective, params_init, args=(X_sensitive_train, X_nonsensitive_train, y_sensitive_train, y_nonsensitive_train, num_prototypes, A_z, A_x, A_y), method='L-BFGS-B')\n",
    "params_opt = result.x\n",
    "\n",
    "# Unpack optimized parameters\n",
    "alpha_sensitive_opt = params_opt[:num_features]\n",
    "alpha_nonsensitive_opt = params_opt[num_features:2*num_features]\n",
    "w_opt = params_opt[2*num_features:(2*num_features + num_prototypes)]\n",
    "V_opt = params_opt[-(num_features * num_prototypes):].reshape((num_prototypes, num_features))\n",
    "\n",
    "# Make predictions on validation and test sets\n",
    "P_val = calculate_probability_matrix(X_val, V_opt, alpha_sensitive_opt if sensitive_val.mean() > 0.5 else alpha_nonsensitive_opt)\n",
    "y_pred_val = np.round(np.dot(P_val, w_opt))\n",
    "\n",
    "P_test = calculate_probability_matrix(X_test, V_opt, alpha_sensitive_opt if sensitive_test.mean() > 0.5 else alpha_nonsensitive_opt)\n",
    "y_pred_test = np.round(np.dot(P_test, w_opt))\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "calibration_val = calc_calibration(sensitive_val, y_pred_val, y_val)\n",
    "\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "calibration_test = calc_calibration(sensitive_test, y_pred_test, y_test)\n",
    "\n",
    "print(f\"Validation Accuracy: {accuracy_val:.4f}\")\n",
    "print(f\"Validation Calibration: {calibration_val:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy_test:.4f}\")\n",
    "print(f\"Test Calibration: {calibration_test:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a836ec69-42cb-44e0-83af-d379e5631046",
   "metadata": {},
   "source": [
    "The baseline model outperforms the Learning Fair Representations (LFR) model in accuracy across training, validation, and test datasets. LFR's decrease in accuracy suggests a trade-off for improved fairness, which is typical for fairness-focused models. However, the LFR model does not show better calibration compared to the baseline, indicating it may not have improved fairness as intended. Higher calibration values in the LFR model, particularly on the test data, suggest that it might be less fair than the baseline, despite the fairness adjustments. To address these issues, further model tuning and investigation into the balance and representation of the sensitive attribute within the data are necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c10f38-8ca0-4f62-99ff-cccfe781e1c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
